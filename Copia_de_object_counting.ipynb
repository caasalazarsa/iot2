{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caasalazarsa/iot2/blob/main/Copia_de_object_counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN1cAxdvd61e"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yaml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://console.paperspace.com/github/ultralytics/ultralytics\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/object_counting.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/models/ultralytics/yolo11\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "\n",
        "Welcome to the Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. This notebook serves as the starting point for exploring the various resources available to help you get started with YOLO11 and understand its features and capabilities.\n",
        "\n",
        "YOLO11 models are fast, accurate, and easy to use, making them ideal for various object detection and image segmentation tasks. They can be trained on large datasets and run on diverse hardware platforms, from CPUs to GPUs.\n",
        "\n",
        "We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/guides/object-counting/\"> Object Counting Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o68Sg1oOeZm2"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://pepy.tech/project/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dSwz_uOReMI",
        "outputId": "fbc639a5-572b-4b65-a505-caba7bd5882c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.27 üöÄ Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 32.1/235.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7VkxQ2aeg7k"
      },
      "source": [
        "# Object Counting using Ultralytics YOLO11 üöÄ\n",
        "\n",
        "## What is Object Counting?\n",
        "\n",
        "Object counting with [Ultralytics YOLO11](https://github.com/ultralytics/ultralytics/) involves accurate identification and counting of specific objects in videos and camera streams. YOLO11 excels in real-time applications, providing efficient and precise object counting for various scenarios like crowd analysis and surveillance, thanks to its state-of-the-art algorithms and deep learning capabilities.\n",
        "\n",
        "## Advantages of Object Counting?\n",
        "\n",
        "- **Resource Optimization:** Object counting facilitates efficient resource management by providing accurate counts, and optimizing resource allocation in applications like inventory management.\n",
        "- **Enhanced Security:** Object counting enhances security and surveillance by accurately tracking and counting entities, aiding in proactive threat detection.\n",
        "- **Informed Decision-Making:** Object counting offers valuable insights for decision-making, optimizing processes in retail, traffic management, and various other domains.\n",
        "\n",
        "## Real World Applications\n",
        "\n",
        "|                                                                           Logistics                                                                           |                                                                     Aquaculture                                                                     |\n",
        "|:-------------------------------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
        "| ![Conveyor Belt Packets Counting Using Ultralytics YOLO11](https://github.com/RizwanMunawar/ultralytics/assets/62513924/70e2d106-510c-4c6c-a57a-d34a765aa757) | ![Fish Counting in Sea using Ultralytics YOLO11](https://github.com/RizwanMunawar/ultralytics/assets/62513924/c60d047b-3837-435f-8d29-bb9fc95d2191) |\n",
        "|                                                    Conveyor Belt Packets Counting Using Ultralytics YOLO11                                                    |                                                    Fish Counting in Sea using Ultralytics YOLO11                                                    |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx-u59HQdu2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4137c8a-f3ca-4114-c7fd-14d370627074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Ultralytics Solutions: ‚úÖ {'region': [(20, 400), (1080, 400)], 'show_in': True, 'show_out': True, 'colormap': None, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'json_file': None, 'show': True, 'model': 'yolo11n.pt', 'line_width': 2}\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 102MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las √∫ltimas 5000 l√≠neas del flujo de salida.\u001b[0m\n",
            "0: 384x640 1 kite, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 vase, 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 14.1ms\n",
            "Speed: 2.3ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 20.6ms\n",
            "Speed: 1.9ms preprocess, 20.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.0ms preprocess, 17.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 16.4ms\n",
            "Speed: 2.0ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 15.0ms\n",
            "Speed: 2.1ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 18.5ms\n",
            "Speed: 2.4ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 13.9ms\n",
            "Speed: 2.8ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 vase, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 vase, 16.6ms\n",
            "Speed: 2.1ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 vase, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 vase, 17.0ms\n",
            "Speed: 2.1ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 1.8ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 1 vase, 22.2ms\n",
            "Speed: 1.8ms preprocess, 22.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 kites, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 kite, 15.5ms\n",
            "Speed: 2.3ms preprocess, 15.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bird, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bird, 1 kite, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bird, 1 kite, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bird, 1 kite, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.3ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.3ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.9ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 1.9ms preprocess, 16.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.0ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.1ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 14.8ms\n",
            "Speed: 2.8ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 17.1ms\n",
            "Speed: 2.0ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 16.6ms\n",
            "Speed: 4.8ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 19.4ms\n",
            "Speed: 2.4ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 11.7ms\n",
            "Speed: 4.4ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 15.1ms\n",
            "Speed: 2.0ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 cell phone, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 cell phone, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 18.6ms\n",
            "Speed: 1.9ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 20.0ms\n",
            "Speed: 1.9ms preprocess, 20.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 19.3ms\n",
            "Speed: 2.4ms preprocess, 19.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 2.0ms preprocess, 20.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.9ms\n",
            "Speed: 1.9ms preprocess, 21.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 3.9ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 4.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.9ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.7ms\n",
            "Speed: 1.9ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 18.2ms\n",
            "Speed: 2.5ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.6ms\n",
            "Speed: 1.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.5ms\n",
            "Speed: 2.1ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 18.9ms\n",
            "Speed: 2.1ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 18.8ms\n",
            "Speed: 1.9ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 19.9ms\n",
            "Speed: 1.9ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 1 cup, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 1 cup, 16.3ms\n",
            "Speed: 2.0ms preprocess, 16.3ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 1 cup, 18.9ms\n",
            "Speed: 4.8ms preprocess, 18.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 1 cup, 19.1ms\n",
            "Speed: 3.0ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 20.4ms\n",
            "Speed: 2.0ms preprocess, 20.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 21.7ms\n",
            "Speed: 1.9ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 15.9ms\n",
            "Speed: 1.9ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 15.8ms\n",
            "Speed: 2.4ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 25.1ms\n",
            "Speed: 2.0ms preprocess, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 17.1ms\n",
            "Speed: 1.9ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 16.7ms\n",
            "Speed: 1.9ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 18.0ms\n",
            "Speed: 3.4ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 17.5ms\n",
            "Speed: 2.1ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 21.1ms\n",
            "Speed: 2.8ms preprocess, 21.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 19.9ms\n",
            "Speed: 2.0ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 19.3ms\n",
            "Speed: 1.9ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 20.5ms\n",
            "Speed: 1.8ms preprocess, 20.5ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 14.3ms\n",
            "Speed: 1.8ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 27.2ms\n",
            "Speed: 1.9ms preprocess, 27.2ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 14.5ms\n",
            "Speed: 1.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 17.1ms\n",
            "Speed: 2.6ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 18.6ms\n",
            "Speed: 2.5ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 23.8ms\n",
            "Speed: 1.9ms preprocess, 23.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 23.4ms\n",
            "Speed: 2.4ms preprocess, 23.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 22.4ms\n",
            "Speed: 2.0ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 16.6ms\n",
            "Speed: 3.2ms preprocess, 16.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 17.9ms\n",
            "Speed: 2.5ms preprocess, 17.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.5ms\n",
            "Speed: 2.1ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.7ms\n",
            "Speed: 2.0ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.5ms\n",
            "Speed: 2.0ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.9ms\n",
            "Speed: 1.8ms preprocess, 16.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 18.7ms\n",
            "Speed: 2.0ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 10.3ms\n",
            "Speed: 2.6ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.1ms\n",
            "Speed: 2.2ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cups, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.4ms\n",
            "Speed: 2.6ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 vase, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cups, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cups, 19.0ms\n",
            "Speed: 2.7ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 cell phone, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 vase, 18.0ms\n",
            "Speed: 4.2ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cups, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 vase, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 1 cup, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 potted plant, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 vase, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 potted plant, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 potted plant, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 potted plant, 14.0ms\n",
            "Speed: 3.9ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 potted plant, 1 vase, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 14.5ms\n",
            "Speed: 2.1ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 18.0ms\n",
            "Speed: 2.3ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cake, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 cell phone, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 cell phone, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 cell phone, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 cell phone, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 1 cell phone, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 12.0ms\n",
            "Speed: 2.6ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 3.7ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 3.3ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.5ms\n",
            "Speed: 2.1ms preprocess, 19.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 15.4ms\n",
            "Speed: 2.0ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.9ms\n",
            "Speed: 2.1ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 17.4ms\n",
            "Speed: 2.0ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 20.2ms\n",
            "Speed: 2.1ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.8ms\n",
            "Speed: 3.2ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 16.0ms\n",
            "Speed: 2.0ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.8ms\n",
            "Speed: 3.6ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 15.8ms\n",
            "Speed: 2.3ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 17.9ms\n",
            "Speed: 2.4ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 14.9ms\n",
            "Speed: 3.2ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 23.6ms\n",
            "Speed: 1.7ms preprocess, 23.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cup, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.8ms\n",
            "Speed: 2.4ms preprocess, 19.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 17.6ms\n",
            "Speed: 1.9ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 17.3ms\n",
            "Speed: 2.0ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 frisbee, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 baseball glove, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cake, 12.6ms\n",
            "Speed: 5.0ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cake, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 cake, 18.0ms\n",
            "Speed: 2.0ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 1 cake, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.3ms\n",
            "Speed: 1.8ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.1ms\n",
            "Speed: 2.0ms preprocess, 16.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.6ms\n",
            "Speed: 3.9ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.6ms\n",
            "Speed: 1.8ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.3ms\n",
            "Speed: 3.3ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.0ms\n",
            "Speed: 1.9ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.9ms\n",
            "Speed: 3.9ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 23.5ms\n",
            "Speed: 6.1ms preprocess, 23.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.0ms\n",
            "Speed: 2.6ms preprocess, 17.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.5ms\n",
            "Speed: 1.9ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 21.4ms\n",
            "Speed: 2.1ms preprocess, 21.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 21.8ms\n",
            "Speed: 2.3ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.5ms\n",
            "Speed: 1.8ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 22.0ms\n",
            "Speed: 1.8ms preprocess, 22.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 19.4ms\n",
            "Speed: 1.9ms preprocess, 19.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 25.5ms\n",
            "Speed: 4.9ms preprocess, 25.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 22.1ms\n",
            "Speed: 1.8ms preprocess, 22.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 20.9ms\n",
            "Speed: 1.9ms preprocess, 20.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.6ms\n",
            "Speed: 2.2ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 18.5ms\n",
            "Speed: 1.9ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.0ms\n",
            "Speed: 2.9ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.7ms\n",
            "Speed: 2.2ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.2ms\n",
            "Speed: 3.3ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 15.6ms\n",
            "Speed: 2.4ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.8ms\n",
            "Speed: 1.7ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 18.5ms\n",
            "Speed: 1.8ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.9ms\n",
            "Speed: 1.9ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 18.5ms\n",
            "Speed: 1.8ms preprocess, 18.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.3ms\n",
            "Speed: 6.2ms preprocess, 16.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.9ms\n",
            "Speed: 2.9ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.1ms\n",
            "Speed: 1.8ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.0ms\n",
            "Speed: 3.4ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 19.6ms\n",
            "Speed: 1.8ms preprocess, 19.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.2ms\n",
            "Speed: 4.3ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 16.7ms\n",
            "Speed: 3.0ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 19.2ms\n",
            "Speed: 2.2ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 20.4ms\n",
            "Speed: 2.1ms preprocess, 20.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 17.8ms\n",
            "Speed: 1.9ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 19.2ms\n",
            "Speed: 2.6ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 18.9ms\n",
            "Speed: 2.4ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cup, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 toothbrushs, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 toothbrush, 11.9ms\n",
            "Speed: 2.7ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toothbrush, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toothbrush, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toothbrush, 12.7ms\n",
            "Speed: 2.6ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toothbrush, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toothbrush, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 toothbrushs, 15.9ms\n",
            "Speed: 1.9ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 toothbrushs, 23.9ms\n",
            "Speed: 1.9ms preprocess, 23.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 toothbrushs, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 toothbrushs, 18.4ms\n",
            "Speed: 1.9ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 toothbrushs, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 2 toothbrushs, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 2 toothbrushs, 17.0ms\n",
            "Speed: 2.0ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 toothbrushs, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 toothbrushs, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toothbrush, 16.4ms\n",
            "Speed: 2.9ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 bottles, 1 book, 1 toothbrush, 18.5ms\n",
            "Speed: 2.2ms preprocess, 18.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 toothbrush, 15.9ms\n",
            "Speed: 1.9ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 19.0ms\n",
            "Speed: 2.0ms preprocess, 19.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 toothbrush, 20.8ms\n",
            "Speed: 2.0ms preprocess, 20.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 toothbrush, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 toothbrush, 18.5ms\n",
            "Speed: 2.1ms preprocess, 18.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 3 books, 18.3ms\n",
            "Speed: 2.2ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 1 toothbrush, 15.0ms\n",
            "Speed: 2.9ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.9ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 2 dining tables, 1 toothbrush, 16.4ms\n",
            "Speed: 2.0ms preprocess, 16.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 2 books, 1 toothbrush, 16.9ms\n",
            "Speed: 2.0ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 25.5ms\n",
            "Speed: 2.6ms preprocess, 25.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 3.8ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 2.0ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.0ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 3.0ms preprocess, 21.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 5.8ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 4.3ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.2ms\n",
            "Speed: 2.1ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.0ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.1ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.7ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 1.8ms preprocess, 16.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 dining table, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 1.9ms preprocess, 16.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.3ms\n",
            "Speed: 3.7ms preprocess, 18.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 19.2ms\n",
            "Speed: 2.4ms preprocess, 19.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 2.7ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 2.0ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 29.5ms\n",
            "Speed: 2.0ms preprocess, 29.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 20.5ms\n",
            "Speed: 3.1ms preprocess, 20.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 19.1ms\n",
            "Speed: 2.2ms preprocess, 19.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 17.7ms\n",
            "Speed: 2.1ms preprocess, 17.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 18.1ms\n",
            "Speed: 2.0ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.5ms\n",
            "Speed: 2.2ms preprocess, 16.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 23.0ms\n",
            "Speed: 7.6ms preprocess, 23.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 2.3ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 30.3ms\n",
            "Speed: 3.6ms preprocess, 30.3ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.5ms\n",
            "Speed: 2.5ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 bottles, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 2.0ms preprocess, 14.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 tie, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 25.4ms\n",
            "Speed: 1.9ms preprocess, 25.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.7ms preprocess, 16.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.1ms\n",
            "Speed: 2.3ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 2.7ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 2.1ms preprocess, 14.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 19.9ms\n",
            "Speed: 2.1ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.1ms\n",
            "Speed: 2.3ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.7ms\n",
            "Speed: 2.1ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.2ms\n",
            "Speed: 3.3ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 20.8ms\n",
            "Speed: 2.0ms preprocess, 20.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.1ms\n",
            "Speed: 2.7ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.9ms\n",
            "Speed: 2.1ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.5ms\n",
            "Speed: 2.0ms preprocess, 17.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 19.3ms\n",
            "Speed: 1.9ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.9ms\n",
            "Speed: 2.9ms preprocess, 18.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 21.3ms\n",
            "Speed: 1.9ms preprocess, 21.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 4.2ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 1.9ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 24.1ms\n",
            "Speed: 2.0ms preprocess, 24.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 21.0ms\n",
            "Speed: 2.9ms preprocess, 21.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 26.7ms\n",
            "Speed: 1.9ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 2.1ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 2.1ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.2ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 2.1ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 27.9ms\n",
            "Speed: 1.9ms preprocess, 27.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.1ms\n",
            "Speed: 2.3ms preprocess, 18.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.4ms\n",
            "Speed: 2.6ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 1.9ms preprocess, 17.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 4.4ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.2ms\n",
            "Speed: 2.3ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 1.7ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 2.0ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 1.9ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.7ms\n",
            "Speed: 2.0ms preprocess, 17.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.6ms\n",
            "Speed: 3.3ms preprocess, 16.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 21.5ms\n",
            "Speed: 3.2ms preprocess, 21.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.0ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 22.2ms\n",
            "Speed: 2.0ms preprocess, 22.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.8ms\n",
            "Speed: 2.0ms preprocess, 18.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 19.2ms\n",
            "Speed: 1.9ms preprocess, 19.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 20.7ms\n",
            "Speed: 1.9ms preprocess, 20.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 20.4ms\n",
            "Speed: 1.9ms preprocess, 20.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 20.5ms\n",
            "Speed: 2.1ms preprocess, 20.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 20.1ms\n",
            "Speed: 2.3ms preprocess, 20.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 21.4ms\n",
            "Speed: 2.0ms preprocess, 21.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 23.2ms\n",
            "Speed: 2.8ms preprocess, 23.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 22.1ms\n",
            "Speed: 2.3ms preprocess, 22.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 21.0ms\n",
            "Speed: 2.0ms preprocess, 21.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.9ms\n",
            "Speed: 2.1ms preprocess, 17.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 2.0ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 1.8ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 2.9ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 2.2ms preprocess, 18.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.8ms\n",
            "Speed: 2.2ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 28.8ms\n",
            "Speed: 2.0ms preprocess, 28.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 20.0ms\n",
            "Speed: 2.0ms preprocess, 20.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.1ms\n",
            "Speed: 3.6ms preprocess, 18.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 24.4ms\n",
            "Speed: 1.9ms preprocess, 24.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 2.5ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 21.8ms\n",
            "Speed: 1.9ms preprocess, 21.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 19.3ms\n",
            "Speed: 2.4ms preprocess, 19.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 20.1ms\n",
            "Speed: 2.0ms preprocess, 20.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.7ms\n",
            "Speed: 2.2ms preprocess, 18.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 22.9ms\n",
            "Speed: 2.0ms preprocess, 22.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 27.5ms\n",
            "Speed: 3.2ms preprocess, 27.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 23.8ms\n",
            "Speed: 3.5ms preprocess, 23.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.0ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 20.1ms\n",
            "Speed: 2.1ms preprocess, 20.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.8ms\n",
            "Speed: 5.2ms preprocess, 16.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 tie, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 tie, 20.6ms\n",
            "Speed: 2.0ms preprocess, 20.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 3 vases, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 4 vases, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 vases, 21.3ms\n",
            "Speed: 1.9ms preprocess, 21.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 vase, 19.2ms\n",
            "Speed: 2.1ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 tie, 2 vases, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 vases, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 vase, 13.6ms\n",
            "Speed: 3.6ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 tie, 1 vase, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 ties, 1 vase, 16.4ms\n",
            "Speed: 4.0ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 vase, 22.3ms\n",
            "Speed: 5.1ms preprocess, 22.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 suitcase, 1 bottle, 19.8ms\n",
            "Speed: 2.2ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 vase, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 1 vase, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 1 vase, 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 19.5ms\n",
            "Speed: 5.1ms preprocess, 19.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 21.8ms\n",
            "Speed: 3.2ms preprocess, 21.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 19.7ms\n",
            "Speed: 2.1ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 23.2ms\n",
            "Speed: 3.9ms preprocess, 23.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 17.1ms\n",
            "Speed: 2.6ms preprocess, 17.1ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 21.6ms\n",
            "Speed: 2.0ms preprocess, 21.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 17.6ms\n",
            "Speed: 2.5ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 20.2ms\n",
            "Speed: 2.3ms preprocess, 20.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 17.6ms\n",
            "Speed: 2.9ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 17.9ms\n",
            "Speed: 2.3ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 18.0ms\n",
            "Speed: 3.7ms preprocess, 18.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 25.5ms\n",
            "Speed: 3.4ms preprocess, 25.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 33.3ms\n",
            "Speed: 2.0ms preprocess, 33.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 21.3ms\n",
            "Speed: 1.9ms preprocess, 21.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 18.9ms\n",
            "Speed: 1.9ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 19.8ms\n",
            "Speed: 2.5ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 17.8ms\n",
            "Speed: 2.1ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 18.0ms\n",
            "Speed: 2.7ms preprocess, 18.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 16.7ms\n",
            "Speed: 2.1ms preprocess, 16.7ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.3ms\n",
            "Speed: 2.1ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.7ms\n",
            "Speed: 4.5ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.6ms\n",
            "Speed: 3.7ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 16.1ms\n",
            "Speed: 2.0ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.1ms\n",
            "Speed: 2.0ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 16.7ms\n",
            "Speed: 2.3ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 vase, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.6ms\n",
            "Speed: 2.2ms preprocess, 14.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.3ms\n",
            "Speed: 2.1ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 clock, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 clock, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 1 clock, 14.9ms\n",
            "Speed: 3.9ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 3 books, 15.5ms\n",
            "Speed: 2.1ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.0ms\n",
            "Speed: 2.0ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 19.3ms\n",
            "Speed: 2.1ms preprocess, 19.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 sports ball, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.2ms preprocess, 16.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 sports ball, 21.8ms\n",
            "Speed: 2.0ms preprocess, 21.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.9ms\n",
            "Speed: 2.5ms preprocess, 16.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 22.3ms\n",
            "Speed: 2.2ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 4.2ms preprocess, 16.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 2.1ms preprocess, 18.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 3.5ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 books, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 books, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 16.6ms\n",
            "Speed: 3.3ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 20.3ms\n",
            "Speed: 2.2ms preprocess, 20.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.4ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 20.2ms\n",
            "Speed: 2.7ms preprocess, 20.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 18.8ms\n",
            "Speed: 4.5ms preprocess, 18.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.6ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 22.2ms\n",
            "Speed: 1.7ms preprocess, 22.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.1ms\n",
            "Speed: 1.9ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 17.8ms\n",
            "Speed: 2.0ms preprocess, 17.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 17.0ms\n",
            "Speed: 2.0ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 23.8ms\n",
            "Speed: 2.2ms preprocess, 23.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 21.3ms\n",
            "Speed: 2.1ms preprocess, 21.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 28.1ms\n",
            "Speed: 2.0ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 24.2ms\n",
            "Speed: 2.3ms preprocess, 24.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 2.5ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.8ms\n",
            "Speed: 2.1ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.4ms\n",
            "Speed: 2.0ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 21.1ms\n",
            "Speed: 3.1ms preprocess, 21.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 19.8ms\n",
            "Speed: 2.2ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.7ms\n",
            "Speed: 3.9ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.7ms\n",
            "Speed: 2.6ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.3ms\n",
            "Speed: 2.1ms preprocess, 18.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.8ms\n",
            "Speed: 2.1ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.2ms\n",
            "Speed: 2.1ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.8ms\n",
            "Speed: 3.6ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.0ms\n",
            "Speed: 2.1ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.4ms\n",
            "Speed: 2.1ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.2ms\n",
            "Speed: 2.1ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 23.5ms\n",
            "Speed: 2.2ms preprocess, 23.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.3ms\n",
            "Speed: 2.3ms preprocess, 18.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 23.9ms\n",
            "Speed: 2.0ms preprocess, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 21.3ms\n",
            "Speed: 2.0ms preprocess, 21.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.5ms\n",
            "Speed: 2.3ms preprocess, 18.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 20.5ms\n",
            "Speed: 1.9ms preprocess, 20.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.7ms\n",
            "Speed: 2.1ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 21.4ms\n",
            "Speed: 1.9ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.7ms\n",
            "Speed: 2.1ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.4ms\n",
            "Speed: 2.1ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 20.5ms\n",
            "Speed: 2.1ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.2ms\n",
            "Speed: 2.0ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.1ms\n",
            "Speed: 3.8ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.2ms\n",
            "Speed: 5.1ms preprocess, 16.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.1ms\n",
            "Speed: 2.1ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.2ms\n",
            "Speed: 2.3ms preprocess, 17.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.6ms\n",
            "Speed: 2.1ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.5ms\n",
            "Speed: 4.1ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.4ms\n",
            "Speed: 2.0ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.2ms\n",
            "Speed: 2.1ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 19.7ms\n",
            "Speed: 2.1ms preprocess, 19.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.6ms\n",
            "Speed: 2.0ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 21.9ms\n",
            "Speed: 1.9ms preprocess, 21.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 26.6ms\n",
            "Speed: 2.0ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 29.9ms\n",
            "Speed: 2.0ms preprocess, 29.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 21.7ms\n",
            "Speed: 4.7ms preprocess, 21.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 20.6ms\n",
            "Speed: 2.4ms preprocess, 20.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.5ms\n",
            "Speed: 2.1ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 1 book, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.3ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.9ms\n",
            "Speed: 1.9ms preprocess, 20.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 2.0ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 3.4ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.2ms\n",
            "Speed: 2.0ms preprocess, 19.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.9ms\n",
            "Speed: 2.3ms preprocess, 16.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.7ms\n",
            "Speed: 2.8ms preprocess, 20.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 4.2ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.7ms\n",
            "Speed: 3.4ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.0ms\n",
            "Speed: 3.1ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 2.1ms preprocess, 22.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.5ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.1ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.3ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 6.2ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.5ms\n",
            "Speed: 2.0ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cake, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 sports ball, 15.3ms\n",
            "Speed: 5.8ms preprocess, 15.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 1 cake, 1 book, 17.0ms\n",
            "Speed: 2.0ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 cake, 2 books, 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 cake, 1 book, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 3 persons, 1 book, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 1 book, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.2ms preprocess, 15.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 2.0ms preprocess, 20.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 5.7ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.1ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.0ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.7ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.0ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.3ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 baseball glove, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 11.3ms\n",
            "Speed: 2.5ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 14.2ms\n",
            "Speed: 1.5ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 14.8ms\n",
            "Speed: 3.4ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 18.6ms\n",
            "Speed: 1.9ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.6ms\n",
            "Speed: 3.2ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 19.0ms\n",
            "Speed: 2.3ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 16.5ms\n",
            "Speed: 2.7ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 24.8ms\n",
            "Speed: 1.9ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 19.3ms\n",
            "Speed: 2.0ms preprocess, 19.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 clock, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 parking meter, 1 clock, 18.1ms\n",
            "Speed: 2.1ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 banana, 1 toilet, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 parking meter, 19.6ms\n",
            "Speed: 3.4ms preprocess, 19.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 toilet, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 22.8ms\n",
            "Speed: 2.1ms preprocess, 22.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 1 tie, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 tie, 15.2ms\n",
            "Speed: 2.7ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 person, 1 tie, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 tie, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 21.8ms\n",
            "Speed: 4.0ms preprocess, 21.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 20.1ms\n",
            "Speed: 2.1ms preprocess, 20.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 16.7ms\n",
            "Speed: 3.2ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 21.8ms\n",
            "Speed: 1.9ms preprocess, 21.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 20.4ms\n",
            "Speed: 2.4ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 22.2ms\n",
            "Speed: 3.8ms preprocess, 22.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 20.8ms\n",
            "Speed: 1.9ms preprocess, 20.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 18.8ms\n",
            "Speed: 1.9ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.6ms\n",
            "Speed: 3.4ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.8ms\n",
            "Speed: 5.6ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 16.7ms\n",
            "Speed: 2.0ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 20.1ms\n",
            "Speed: 2.4ms preprocess, 20.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 16.0ms\n",
            "Speed: 4.9ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 17.8ms\n",
            "Speed: 1.9ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 17.5ms\n",
            "Speed: 3.1ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 19.7ms\n",
            "Speed: 2.0ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 28.3ms\n",
            "Speed: 1.9ms preprocess, 28.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 17.0ms\n",
            "Speed: 2.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 21.4ms\n",
            "Speed: 2.0ms preprocess, 21.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 27.9ms\n",
            "Speed: 2.0ms preprocess, 27.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 18.3ms\n",
            "Speed: 2.1ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 19.1ms\n",
            "Speed: 4.4ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 21.1ms\n",
            "Speed: 1.9ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 16.8ms\n",
            "Speed: 2.4ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.7ms\n",
            "Speed: 2.2ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 knife, 15.7ms\n",
            "Speed: 6.9ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 2 knifes, 16.2ms\n",
            "Speed: 2.0ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 3 knifes, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 knife, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 knife, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 knife, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 knife, 1 book, 17.0ms\n",
            "Speed: 3.1ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.0ms\n",
            "Speed: 2.1ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 17.9ms\n",
            "Speed: 2.1ms preprocess, 17.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 15.6ms\n",
            "Speed: 2.1ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 16.2ms\n",
            "Speed: 2.1ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 knife, 20.9ms\n",
            "Speed: 3.5ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "\n",
            "0: 384x640 1 book, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 book, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 tie, 2 books, 13.6ms\n",
            "Speed: 2.6ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 books, 18.5ms\n",
            "Speed: 3.5ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.3ms\n",
            "Speed: 2.8ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.1ms\n",
            "Speed: 2.0ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 24.2ms\n",
            "Speed: 2.9ms preprocess, 24.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 18.4ms\n",
            "Speed: 3.5ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.1ms\n",
            "Speed: 1.8ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 19.5ms\n",
            "Speed: 2.1ms preprocess, 19.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 22.5ms\n",
            "Speed: 1.9ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.2ms\n",
            "Speed: 3.3ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.8ms\n",
            "Speed: 2.8ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 18.8ms\n",
            "Speed: 3.0ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.5ms\n",
            "Speed: 2.0ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.9ms\n",
            "Speed: 3.4ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.3ms\n",
            "Speed: 2.1ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.9ms\n",
            "Speed: 2.2ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.0ms\n",
            "Speed: 2.6ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 20.1ms\n",
            "Speed: 3.4ms preprocess, 20.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.7ms\n",
            "Speed: 1.9ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.0ms\n",
            "Speed: 2.2ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.6ms\n",
            "Speed: 2.6ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.0ms\n",
            "Speed: 2.0ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.3ms\n",
            "Speed: 2.0ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.8ms\n",
            "Speed: 2.1ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.3ms\n",
            "Speed: 2.2ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.4ms\n",
            "Speed: 4.1ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.5ms\n",
            "Speed: 3.2ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.2ms\n",
            "Speed: 3.7ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 20.0ms\n",
            "Speed: 1.9ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 23.0ms\n",
            "Speed: 2.0ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 21.8ms\n",
            "Speed: 2.3ms preprocess, 21.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 19.6ms\n",
            "Speed: 1.9ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 21.2ms\n",
            "Speed: 1.8ms preprocess, 21.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 19.7ms\n",
            "Speed: 1.9ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 19.4ms\n",
            "Speed: 4.3ms preprocess, 19.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.8ms\n",
            "Speed: 2.7ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.7ms\n",
            "Speed: 1.9ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 23.0ms\n",
            "Speed: 2.8ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.4ms\n",
            "Speed: 1.9ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 24.9ms\n",
            "Speed: 2.0ms preprocess, 24.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 19.8ms\n",
            "Speed: 2.0ms preprocess, 19.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.9ms\n",
            "Speed: 2.1ms preprocess, 17.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 2.6ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 19.6ms\n",
            "Speed: 2.1ms preprocess, 19.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.7ms\n",
            "Speed: 2.3ms preprocess, 17.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 22.2ms\n",
            "Speed: 2.1ms preprocess, 22.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.3ms\n",
            "Speed: 2.0ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.0ms\n",
            "Speed: 4.2ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 18.1ms\n",
            "Speed: 2.4ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.9ms\n",
            "Speed: 1.9ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.9ms\n",
            "Speed: 1.9ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 20.3ms\n",
            "Speed: 2.1ms preprocess, 20.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 24.5ms\n",
            "Speed: 1.9ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 18.1ms\n",
            "Speed: 2.3ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 22.0ms\n",
            "Speed: 2.0ms preprocess, 22.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.4ms\n",
            "Speed: 2.0ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.0ms\n",
            "Speed: 1.9ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 18.6ms\n",
            "Speed: 2.0ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 21.0ms\n",
            "Speed: 1.9ms preprocess, 21.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 18.7ms\n",
            "Speed: 1.8ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 24.6ms\n",
            "Speed: 2.0ms preprocess, 24.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 25.6ms\n",
            "Speed: 2.9ms preprocess, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 18.9ms\n",
            "Speed: 2.9ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.2ms\n",
            "Speed: 2.7ms preprocess, 17.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 22.8ms\n",
            "Speed: 2.0ms preprocess, 22.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 20.1ms\n",
            "Speed: 2.0ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.2ms\n",
            "Speed: 2.1ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.1ms\n",
            "Speed: 1.9ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.9ms\n",
            "Speed: 2.1ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.4ms\n",
            "Speed: 2.2ms preprocess, 16.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.6ms\n",
            "Speed: 2.0ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 21.9ms\n",
            "Speed: 3.7ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 28.0ms\n",
            "Speed: 2.8ms preprocess, 28.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 25.6ms\n",
            "Speed: 2.3ms preprocess, 25.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.4ms\n",
            "Speed: 2.6ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.4ms\n",
            "Speed: 2.3ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.0ms\n",
            "Speed: 2.2ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.1ms\n",
            "Speed: 2.2ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 14.7ms\n",
            "Speed: 3.2ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 17.7ms\n",
            "Speed: 7.7ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 15.5ms\n",
            "Speed: 2.1ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 20.4ms\n",
            "Speed: 2.1ms preprocess, 20.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 books, 1 toothbrush, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video frame is empty or video processing has been successfully completed.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "from ultralytics import solutions\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/testvideo.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "# Get video properties: width, height, and frames per second (fps)\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define points for a line or region of interest in the video frame\n",
        "line_points = [(20, 400), (1080, 400)]  # Line coordinates\n",
        "\n",
        "# Initialize the video writer to save the output video\n",
        "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Initialize the Object Counter with visualization options and other parameters\n",
        "counter = solutions.ObjectCounter(\n",
        "    show=True,  # Display the image during processing\n",
        "    region=line_points,  # Region of interest points\n",
        "    model=\"yolo11n.pt\",  # Ultralytics YOLO11 model file\n",
        "    line_width=2,  # Thickness of the lines and bounding boxes\n",
        ")\n",
        "\n",
        "# Process video frames in a loop\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    # Use the Object Counter to count objects in the frame and get the annotated image\n",
        "    im0 = counter.count(im0)\n",
        "\n",
        "    # Write the annotated frame to the output video\n",
        "    video_writer.write(im0)\n",
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "\n",
        "# Close all OpenCV windows\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrlKg-y3fEyD"
      },
      "source": [
        "# Additional Resources\n",
        "\n",
        "## Community Support\n",
        "\n",
        "For more information on counting objects with Ultralytics, you can explore the comprehensive [Ultralytics Object Counting Docs](https://docs.ultralytics.com/guides/object-counting/). This guide covers everything from basic concepts to advanced techniques, ensuring you get the most out of counting and visualization.\n",
        "\n",
        "## Ultralytics ‚ö° Resources\n",
        "\n",
        "At Ultralytics, we are committed to providing cutting-edge AI solutions. Here are some key resources to learn more about our company and get involved with our community:\n",
        "\n",
        "- [Ultralytics HUB](https://ultralytics.com/hub): Simplify your AI projects with Ultralytics HUB, our no-code tool for effortless YOLO training and deployment.\n",
        "- [Ultralytics Licensing](https://ultralytics.com/license): Review our licensing terms to understand how you can use our software in your projects.\n",
        "- [About Us](https://ultralytics.com/about): Discover our mission, vision, and the story behind Ultralytics.\n",
        "- [Join Our Team](https://ultralytics.com/work): Explore career opportunities and join our team of talented professionals.\n",
        "\n",
        "## YOLO11 üöÄ Resources\n",
        "\n",
        "YOLO11 is the latest evolution in the YOLO series, offering state-of-the-art performance in object detection and image segmentation. Here are some essential resources to help you get started with YOLO11:\n",
        "\n",
        "- [GitHub](https://github.com/ultralytics/ultralytics): Access the YOLO11 repository on GitHub, where you can find the source code, contribute to the project, and report issues.\n",
        "- [Docs](https://docs.ultralytics.com/): Explore the official documentation for YOLO11, including installation guides, tutorials, and detailed API references.\n",
        "- [Discord](https://ultralytics.com/discord): Join our Discord community to connect with other users, share your projects, and get help from the Ultralytics team.\n",
        "\n",
        "These resources are designed to help you leverage the full potential of Ultralytics' offerings and YOLO11. Whether you're a beginner or an experienced developer, you'll find the information and support you need to succeed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}